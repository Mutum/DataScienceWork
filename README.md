# Data Science Work
This repository contains my submissions for several challenges on Kaggle and other data science projects

## [Bike Sharing Demand](https://github.com/ayushoriginal/DataScienceWork/tree/master/BikeSharingDemand)
### AIM: Forecast use of a city bikeshare system

Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.

The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.

The goal of this challenge is to build a model that predicts the count of bike shared, exclusively based on contextual features. The first part of this challenge was aimed to understand, to analyse and to process those dataset. I wanted to produce meaningful information with plots. The second part was to build a model and use a Machine Learning library in order to predict the count.

The more importants parameters were the time, the month, the temperature and the weather.  
Multiple models were tested during this challenge (Linear Regression, Gradient Boosting, SVR and Random Forest). Finally, the chosen model was Random Forest. The accuracy was measured with [Out-of-Bag Error](https://www.stat.berkeley.edu/~breiman/OOBestimation.pdf) and the OOB score was 0.85.

![0](https://i.imgur.com/TXkwAFo.jpg)


## [NYC Taxi Trips](https://github.com/ayushoriginal/DataScienceWork/tree/master/TaxiTrip)
### AIM: Predict the total ride duration of taxis

The challenge is to build a model that predicts the total ride duration of taxi trips in New York City. The primary dataset is one released by the NYC Taxi and Limousine Commission, which includes pickup time, geo-coordinates, number of passengers, and several other variables.

![1](https://i.imgur.com/cIS5qSF.png)
### First part - Data exploration
The first part is to analyze the dataframe and observe correlation between variables.
![Distributions](https://github.com/ayushoriginal/DataScienceWork/blob/master/TaxiTrip/pic/download.png)
![Rush Hour](https://github.com/ayushoriginal/DataScienceWork/blob/master/TaxiTrip/pic/rush_hour.png)

### Second part - Clustering
The goal of this playground is to predict the trip duration of test set. We know that some neighborhoods are more congested. So, I used K-Means to compute geo-clusters for pickup and drop off.
![Cluster](https://github.com/ayushoriginal/DataScienceWork/blob/master/TaxiTrip/pic/nyc_clusters.png)

### Third part - Cleaning and feature selection 
I have found some odd long trips : one day trip with a mean spead < 1km/h.   
![Outliners](https://github.com/ayushoriginal/DataScienceWork/blob/master/TaxiTrip/pic/outliners.png)
I have removed these outliners.  

I also added features from the data available : Haversine distance, Manhattan distance, means for clusters, PCA for rotation.

### Forth part - Prediction
I compared Random Forest and XGBoost.  
Current Root Mean Squared Logarithmic error : 0.391

Feature importance for RF & XGBoost
![Feature importance](https://github.com/ayushoriginal/DataScienceWork/blob/master/TaxiTrip/pic/feat_importance.png)


## [Face Recognition](https://github.com/ayushoriginal/DataScienceWork/tree/master/FaceRecognition)
### AIM: Predict keypoint positions on face images
The objective of this task is to predict keypoint positions on face images. This can be used as a building block in several applications, such as:

-tracking faces in images and video
-analysing facial expressions
-detecting dysmorphic facial signs for medical diagnosis
-biometrics / face recognition

Detecing facial keypoints is a very challenging problem.  Facial features vary greatly from one individual to another, and even for a single individual, there is a large amount of variation due to 3D pose, size, position, viewing angle, and illumination conditions. Computer vision research has come a long way in addressing these difficulties, but there remain many opportunities for improvement.
Modern face recognition with deep learning and HOG algorithm. Using dlib C++ library, I have a quick face recognition tool using few pictures

Modern face recognition with deep learning and HOG algorithm.  

1. Find faces in image (HOG Algorithm)   
2. Affine Transformations (Face alignment using an ensemble of regression
trees)   
3. Encoding Faces (FaceNet)  
4. Make a prediction (Linear SVM)  

We are using the [Histogram of Oriented Gradients](http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf) (HOG) method. Instead of computing gradients for every pixel of the image (way too much detail). We compute the weighted vote orientation  gradients of 16x16 pixels squares. Afterward, we have a simple representation (HOG image) that captures the basic structure of a face.  
All we have to do is find the part of our image that looks the most similar to a known trained HOG pattern.  
For this technique, we use the dlib Python library to generate and view HOG representations of images.  
```
face_detector = dlib.get_frontal_face_detector()
detected_faces = face_detector(image, 1)
```

After isolating the faces in our image, we need to warp (posing and projecting)the picture so the face is always in he same place. To do this, we are going to use the [face landmark estimation algorithm](http://www.csc.kth.se/~vahidk/papers/KazemiCVPR14.pdf). Following this method, there are 68 specific points (landmarks) on every face and we train a machine learning algorithm to find these 68 specific points on any face. 
```
face_pose_predictor = dlib.shape_predictor(predictor_model)
pose_landmarks = face_pose_predictor(img, f)
```
After find those landmarks, we need to use affine transformations (such as rotating, scaling and shearing --like translations) on the image so that the eyes and mouth are centered as best as possible.
```
face_aligner = openface.AlignDlib(predictor_model)
alignedFace = face_aligner.align(534, image, face_rect, landmarkIndices=openface.AlignDlib.OUTER_EYES_AND_NOSE)
```

The next step is encoding the detected face. For this, we use Deep Learning. We train a neural net to generate [128 measurements (face embedding)](http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/1A_089.pdf) for each face.  
The training process works by looking at 3 face images at a time:  
- Load two training face images of the same known person and generate for the two pictures the 128 measurements
- Load a picture of a  different person and generate for the two pictures the 128 measurements  
Then we tweak the neural network slightly so that it makes sure the measurements for the same person are slightly closer while making sure the measurements for the two different persons are slightly further apart.
Once the network has been trained, it can generate measurements for any face, even ones it has never seen before!
```
face_encoder = dlib.face_recognition_model_v1(face_recognition_model)
face_encoding = np.array(face_encoder.compute_face_descriptor(image, pose_landmarks, 1))
```

Finally, we need a classifier (Linear SVM or other classifier) to find the person in our database of known people who has the closest measurements to our test image. We train the classifier with the measurements as input.

Thanks to Adam Geitgey who wrote a great [post](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78) about this, I followed his pipeline.

![Result](https://github.com/ayushoriginal/DataScienceWork/blob/master/FaceRecognition/result.png)



## [Playing with Soccer data](https://github.com/ayushoriginal/DataScienceWork/tree/master/Soccer)
As a soccer fan and a data passionate, I wanted to play and analyze with soccer data.  
I don't know currently what's the aim of this project but I will parse data from diverse websites, for differents teams and differents players. 


## [Kaggle Understanding the Amazon from Space](https://github.com/ayushoriginal/DataScienceWork/tree/master/Amazon) 
Use satellite data to track the human footprint in the Amazon rainforest.  
Deep Learning model (using Keras) to label satellite images.

## [Predicting IMDB movie rating](https://github.com/ayushoriginal/DataScienceWork/tree/master/MovieRating)
Project inspired by Chuan Sun [work](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset)  
How can we tell the greatness of a movie ?  
 
## [Twitter Parsing](https://github.com/ayushoriginal/DataScienceWork/tree/master/TwitterParsing)
###AIM: Check every 2 hours, if Chris Albon has posted new flash cards. In this case, download them and send me a summary email.

I've recently discovered the Chris Albon Machine Learning flash cards and I want to download those flash cards but the official Twitter API has a limit rate of 2 weeks old tweets so I had to find a way to bypass this limitation : use Selenium and PhantomJS.
